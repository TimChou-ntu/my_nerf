{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms as T\n",
    "\n",
    "img = Image.open(\"./nerf_synthetic/lego/train/r_0.png\")\n",
    "img = img.resize((400,400), Image.LANCZOS)\n",
    "img = T.ToTensor()(img)\n",
    "print(img.shape)\n",
    "# valid_mask = (img[-1]>0).flatten()\n",
    "valid_mask = (img[-1]>0)\n",
    "print(img.permute(1,2,0)[valid_mask]*256)\n",
    "print(valid_mask.sum())\n",
    "img = img.view(4,-1).permute(1,0)\n",
    "print(img.shape)\n",
    "img = img[:, :3]*img[:, -1:] + (1-img[:, -1:])\n",
    "img = img.view(400,400,3)\n",
    "print(img.shape)\n",
    "print(img[valid_mask]*256)\n",
    "# img = img.permute(1,0).view(3, 400, 400)\n",
    "# img = T.ToPILImage()(img)\n",
    "# img.save('test.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import transform\n",
    "import numpy as np\n",
    "def blender_quat2rot(quaternion):\n",
    "  \"\"\"Convert quaternion to rotation matrix.\n",
    "  Equivalent to, but support batched case:\n",
    "  ```python\n",
    "  rot3x3 = mathutils.Quaternion(quaternion).to_matrix()\n",
    "  ```\n",
    "  Args:\n",
    "    quaternion:\n",
    "  Returns:\n",
    "    rotation matrix\n",
    "  \"\"\"\n",
    "\n",
    "  # Note: Blender first cast to double values for numerical precision while\n",
    "  # we're using float32.\n",
    "  q = np.sqrt(2) * quaternion\n",
    "\n",
    "  q0 = q[..., 0]\n",
    "  q1 = q[..., 1]\n",
    "  q2 = q[..., 2]\n",
    "  q3 = q[..., 3]\n",
    "\n",
    "  qda = q0 * q1\n",
    "  qdb = q0 * q2\n",
    "  qdc = q0 * q3\n",
    "  qaa = q1 * q1\n",
    "  qab = q1 * q2\n",
    "  qac = q1 * q3\n",
    "  qbb = q2 * q2\n",
    "  qbc = q2 * q3\n",
    "  qcc = q3 * q3\n",
    "\n",
    "  # Note: idx are inverted as blender and numpy convensions do not\n",
    "  # match (x, y) -> (y, x)\n",
    "  rotation = np.empty((*quaternion.shape[:-1], 3, 3), dtype=np.float32)\n",
    "  rotation[..., 0, 0] = 1.0 - qbb - qcc\n",
    "  rotation[..., 1, 0] = qdc + qab\n",
    "  rotation[..., 2, 0] = -qdb + qac\n",
    "\n",
    "  rotation[..., 0, 1] = -qdc + qab\n",
    "  rotation[..., 1, 1] = 1.0 - qaa - qcc\n",
    "  rotation[..., 2, 1] = qda + qbc\n",
    "\n",
    "  rotation[..., 0, 2] = qdb + qac\n",
    "  rotation[..., 1, 2] = -qda + qbc\n",
    "  rotation[..., 2, 2] = 1.0 - qaa - qbb\n",
    "  return rotation\n",
    "\n",
    "def make_transform_matrix(positions,rotations,):\n",
    "  \"\"\"Create the 4x4 transformation matrix.\n",
    "  Note: This function uses numpy.\n",
    "  Args:\n",
    "    positions: Translation applied after the rotation.\n",
    "      Last column of the transformation matrix\n",
    "    rotations: Rotation. Top-left 3x3 matrix of the transformation matrix.\n",
    "  Returns:\n",
    "    transformation_matrix:\n",
    "  \"\"\"\n",
    "  # Create the 4x4 transformation matrix\n",
    "  rot_pos = np.broadcast_to(np.eye(4), (*positions.shape[:-1], 4, 4)).copy()\n",
    "  rot_pos[..., :3, :3] = rotations\n",
    "  rot_pos[..., :3, 3] = positions\n",
    "  return rot_pos\n",
    "\n",
    "def from_position_and_quaternion(positions, quaternions, use_unreal_axes):\n",
    "    if use_unreal_axes:\n",
    "      rotations = transform.Rotation.from_quat(quaternions).as_matrix()\n",
    "    else:\n",
    "      # Rotation matrix that rotates from world to object coordinates.\n",
    "      # Warning: Rotations should be given in blender convensions as\n",
    "      # scipy.transform uses different convensions.\n",
    "      rotations = blender_quat2rot(quaternions)\n",
    "    px2world_transform = make_transform_matrix(positions=positions,rotations=rotations)\n",
    "    return px2world_transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "with open(\"/home/timothy/Desktop/2023Spring/GeoNeRF/data/data/nesf_data/klevr/0/metadata.json\",\"r\") as f:\n",
    "    file = json.load(f)\n",
    "    # print(file['metadata']) # {'width': 256, 'height': 256, 'num_frames': 301, 'seed': 0}\n",
    "    # print(file['camera'].keys()) # dict_keys(['focal_length', 'sensor_width', 'field_of_view', 'positions', 'quaternions', 'K', 'R', 'height', 'width'])\n",
    "    # print(file['segmentation_labels']) # ['Cube', 'Cylinder', 'Sphere', 'Torus', 'Gear']\n",
    "    # print(file['scene_boundaries']) # {'min': [-3.1, -3.1, -0.1], 'max': [3.1, 3.1, 3.1]}\n",
    "    # print(file['split_ids']) # {\"train\": [0, 1], \"test\": [2]}} ...\n",
    "\n",
    "positions = np.array(file['camera']['positions'])     # (301, 3)\n",
    "quaternions = np.array(file['camera']['quaternions']) # (301, 4)\n",
    "focal_px_length = file['camera']['focal_length'] * file['metadata']['width'] / file['camera']['sensor_width']\n",
    "\n",
    "# print(positions.shape)\n",
    "# print(quaternions.shape)\n",
    "\n",
    "px2world_transform = from_position_and_quaternion(positions, quaternions, False)\n",
    "print(px2world_transform.shape)                         # (301,4,4)\n",
    "# print(file['camera']['K'])\n",
    "# print(file['camera']['R'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 128])\n",
      "tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]]])\n",
      "tensor([0, 1, 2, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "import PIL.Image as Image\n",
    "from torchvision import transforms as T\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# label_list = []\n",
    "# for i in range(200):\n",
    "#     img = Image.open(f\"/home/timothy/Desktop/2023Spring/GeoNeRF/data/data/nesf_data/klevr/{i}/segmentation_00010.png\")\n",
    "#     # img = Image.open(\"/home/timothy/Desktop/2023Spring/GeoNeRF/data/data/nesf_data/klevr/1/rgba_00000.png\")\n",
    "#     labels = np.unique(np.array(img))\n",
    "#     for label in labels:\n",
    "#         if label not in label_list:\n",
    "#             label_list.append(label)\n",
    "\n",
    "# print(label_list)\n",
    "\n",
    "img = Image.open(f\"/home/timothy/Desktop/2023Spring/GeoNeRF/data/data/nesf_data/klevr/{i}/segmentation_00010.png\")\n",
    "img = img.resize((128,128), Image.Resampling.LANCZOS)\n",
    "img = torch.from_numpy(np.array(img)).long().unsqueeze(-1)\n",
    "print(img.shape)\n",
    "print(img)\n",
    "unique = torch.unique(img)\n",
    "print(unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n",
      "[3, 15, 20, 22, 27, 30, 34, 37, 42, 44, 47, 49, 51, 52, 53, 54, 57, 60, 61, 72, 75, 77, 78, 79, 84, 86, 89, 91, 96, 98, 99, 102, 104, 110, 113, 114, 117, 119, 121, 122, 124, 126, 130, 135, 140, 144, 148, 150, 154, 157, 159, 160, 166, 171, 177, 178, 180, 181, 187, 188, 189, 192, 195, 196, 205, 209, 211, 220, 225, 227, 229, 231, 242, 244, 252, 253, 254, 259, 263, 264, 270, 274, 275, 277, 285, 289, 292, 296, 297, 299, 300]\n"
     ]
    }
   ],
   "source": [
    "x = [60, 84, 205, 159, 91, 242, 53, 42, 126, 135, 270, 154, 189, 22, 15, 98, 180, 227, 34, 72, 27, 89, 30, 178, 150, 122, 99, 86, 144, 225, 181, 231, 61, 51, 52, 177, 57, 211, 157, 47, 3, 20, 113, 77, 220, 79, 264, 148, 49, 244, 119, 300, 263, 78, 252, 275, 274, 166, 285, 102, 299, 44, 253, 104, 75, 110, 171, 37, 117, 254, 54, 209, 114, 192, 196, 296, 292, 229, 130, 195, 297, 96, 289, 188, 277, 160, 121, 259, 140, 124, 187]\n",
    "x = sorted(x)\n",
    "print(len(x))\n",
    "print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nerf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9d3c896b3482121207db9fe45bcc9d87ea21293b939318b6b7157edd46f95c75"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
